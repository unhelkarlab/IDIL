{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/juanhevia/IDIL\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import idil_gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"LD_LIBRARY_PATH\"] = os.environ.get(\"LD_LIBRARY_PATH\", \"\") + \":/home/juanhevia/.mujoco/mujoco210/bin\" + \":/usr/lib/nvidia\"\n",
    "\n",
    "#import gymnasium\n",
    "# import gym\n",
    "import json \n",
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "#import minari\n",
    "# can we use the vector distance between the achieved and desired goal as a termination mark?\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check proportion of macro goal sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train sequences\n",
    "with open(\"notebooks/kitchen_franka_demos/FrankaKitchen-v0-mixed_260.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "rows = []\n",
    "\n",
    "for traj in data[\"latents\"]:\n",
    "    _count = Counter(traj)\n",
    "    # build JSON object as row\n",
    "    rows.append(_count)\n",
    "\n",
    "# convert to DataFrame\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    True\n",
       "4    True\n",
       "2    True\n",
       "0    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_combs = []\n",
    "for latent in data[\"latents\"]:\n",
    "    # compute the unique latents in the sequence without losing their order of appearance\n",
    "    _unique = []\n",
    "    for l in latent:\n",
    "        if l not in _unique:\n",
    "            _unique.append(l)\n",
    "    \n",
    "    unique_combs.append(tuple(_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(1, 4, 2): 68,\n",
       "         (0, 4, 2): 86,\n",
       "         (4, 2): 1,\n",
       "         (0, 1, 4): 44,\n",
       "         (0, 1, 2): 61})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(unique_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Counter(unique_combs).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split `pkl` files by macro goal sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4, 2), (0, 4, 2), (0, 1, 4), (0, 1, 2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_seqs = list(Counter(unique_combs).keys())\n",
    "# keep only 3-goals sequences\n",
    "available_seqs = [seq for seq in available_seqs if len(seq) == 3]\n",
    "available_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(1, 4, 2), (0, 4, 2), (0, 1, 4), (0, 1, 2)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "seqs_trajs = defaultdict(list)\n",
    "\n",
    "# create a dict to hold trajectories indices for each sequence\n",
    "for traj_idx, traj in enumerate(data[\"latents\"]):\n",
    "    # compute the unique latents in the sequence without losing their order of appearance\n",
    "    _unique = []\n",
    "    for l in traj:\n",
    "        if l not in _unique:\n",
    "            _unique.append(l)\n",
    "            \n",
    "    if tuple(_unique) in available_seqs:\n",
    "        seqs_trajs[tuple(_unique)].append(traj_idx)\n",
    "    \n",
    "seqs_trajs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 2)  --> # of records =  68\n",
      "(0, 4, 2)  --> # of records =  86\n",
      "(0, 1, 4)  --> # of records =  44\n",
      "(0, 1, 2)  --> # of records =  61\n"
     ]
    }
   ],
   "source": [
    "# check that lengths are the same\n",
    "for seq, trajs in seqs_trajs.items():\n",
    "    print(seq, \" --> # of records = \", len(trajs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dictionaries to hold the sequences and the corresponding trajectories\n",
    "split_data = {}\n",
    "\n",
    "for seq, traj_indices in seqs_trajs.items():\n",
    "    split_data[seq] = defaultdict(list)\n",
    "\n",
    "    for key in data.keys():\n",
    "        for idx in traj_indices:\n",
    "            split_data[seq][key].append(data[key][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 2)  --> keys :  dict_keys(['states', 'next_states', 'actions', 'rewards', 'latents', 'lengths', 'dones'])\n",
      "(1, 4, 2)  --> # of records =  68\n",
      "(0, 4, 2)  --> keys :  dict_keys(['states', 'next_states', 'actions', 'rewards', 'latents', 'lengths', 'dones'])\n",
      "(0, 4, 2)  --> # of records =  86\n",
      "(0, 1, 4)  --> keys :  dict_keys(['states', 'next_states', 'actions', 'rewards', 'latents', 'lengths', 'dones'])\n",
      "(0, 1, 4)  --> # of records =  44\n",
      "(0, 1, 2)  --> keys :  dict_keys(['states', 'next_states', 'actions', 'rewards', 'latents', 'lengths', 'dones'])\n",
      "(0, 1, 2)  --> # of records =  61\n"
     ]
    }
   ],
   "source": [
    "# compute lengths of the sequences in the split data\n",
    "for seq, data in split_data.items():\n",
    "    print(seq, \" --> keys : \", data.keys())\n",
    "    print(seq, \" --> # of records = \", len(data[\"latents\"]))\n",
    "\n",
    "    # ensure all keys in the data have equal length\n",
    "    for key in data.keys():\n",
    "        assert len(data[key]) == len(data[\"latents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "176\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "print(len(split_data[(0, 1, 2)][\"states\"][0]))\n",
    "print(len(split_data[(0, 1, 2)][\"next_states\"][0]))\n",
    "print(split_data[(0, 1, 2)][\"lengths\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the split data to different pickle files\n",
    "for seq, data in split_data.items():\n",
    "    seq_label = \"_\".join([str(s) for s in seq])\n",
    "    # with open(f\"notebooks/kitchen_franka_demos/FrankaKitchen-v0-mixed_260_{seq_label}.pkl\", \"wb\") as f:\n",
    "    with open(f\"idil_train/experts//FrankaKitchen-v0-mixed_260_{seq_label}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

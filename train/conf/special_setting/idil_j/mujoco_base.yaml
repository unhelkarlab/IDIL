# @package _global_

max_explore_step: 1e6

n_traj: 5
n_sample: 50000
init_sample: 1000
update_interval: 5
mini_batch_size: 256
demo_latent_infer_interval: 1000

# Q-net
hidden_critic: [256, 256]
optimizer_lr_critic: 3.e-4
method_loss: value
# policy
hidden_policy: [256, 256]
optimizer_lr_policy: 3e-5
# option
hidden_option: [256, 256]
optimizer_lr_option: 3e-5
# alpha
optimizer_lr_alpha: 3.e-4
init_temp: 1e-2
learn_temp: False
